{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import RepeatedKFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-30T05:55:12.608123Z","iopub.execute_input":"2023-01-30T05:55:12.608753Z","iopub.status.idle":"2023-01-30T05:55:12.614408Z","shell.execute_reply.started":"2023-01-30T05:55:12.608719Z","shell.execute_reply":"2023-01-30T05:55:12.613318Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"Here are examples of loading data with different formats. ","metadata":{}},{"cell_type":"code","source":"import os\nimport json\ndef read_csv_space(path, file):\n    return pd.read_csv(os.path.join(path, file), encoding='', sep='\\s+', index_col=False, engine='python') \n\ndef read_csv_comma(path, file):\n    return pd.read_csv(os.path.join(path, file), encoding='', sep=',', engine='python') \n\ndef json_load(path, file):\n    with open(os.path.join(path, file), encoding='', mode='r') as f:\n        v = json.load(f)\n        f.close()\n    return v\n\ndef read_text(path, file):\n    with open(os.path.join(path, file),encoding='', mode='r') as f:\n        lines = []\n        for l in f:\n            lines.append(l.rstrip('\\n').split('\\t'))\n    return lines \n\ndef table_load(self, path, file_name):\n    df = pd.read_excel(os.path.join(path, file_name), engine='openpyxl', sheet_name=0)\n    mylist = df['words'].tolist()\n    return mylist","metadata":{"execution":{"iopub.status.busy":"2023-01-30T05:55:12.633298Z","iopub.execute_input":"2023-01-30T05:55:12.633699Z","iopub.status.idle":"2023-01-30T05:55:12.646011Z","shell.execute_reply.started":"2023-01-30T05:55:12.633669Z","shell.execute_reply":"2023-01-30T05:55:12.644259Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"markdown","source":"We still use the Boston housing price data for demostration. ","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(action='ignore', category=FutureWarning) \nfrom sklearn.datasets import load_boston\nboston=load_boston()\nboston_df=pd.DataFrame(boston.data,columns=boston.feature_names)\nboston_df['Price']=boston.target\nxmat=boston_df.drop('Price',axis=1)\ny =boston_df['Price']\nX_list = xmat.columns \nprint(X_list)\nlen(boston_df)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T05:55:12.648031Z","iopub.execute_input":"2023-01-30T05:55:12.648677Z","iopub.status.idle":"2023-01-30T05:55:12.669542Z","shell.execute_reply.started":"2023-01-30T05:55:12.648640Z","shell.execute_reply":"2023-01-30T05:55:12.668588Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n       'PTRATIO', 'B', 'LSTAT'],\n      dtype='object')\n","output_type":"stream"},{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"506"},"metadata":{}}]},{"cell_type":"markdown","source":"Split data into training and test sample. ","metadata":{}},{"cell_type":"code","source":"X_train,X_test,y_train,y_test=train_test_split(xmat,y,test_size=0.2,random_state=3)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T05:55:12.670931Z","iopub.execute_input":"2023-01-30T05:55:12.671968Z","iopub.status.idle":"2023-01-30T05:55:12.679414Z","shell.execute_reply.started":"2023-01-30T05:55:12.671932Z","shell.execute_reply":"2023-01-30T05:55:12.678038Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"markdown","source":"Linear regression ","metadata":{}},{"cell_type":"code","source":"reg = LinearRegression()\nreg.fit(X_train, y_train)\ntrain_score=reg.score(X_train,y_train)\ntest_score=reg.score(X_test,y_test)\nprint(test_score)\nprint(reg.coef_)\nyhat = reg.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T05:55:12.681813Z","iopub.execute_input":"2023-01-30T05:55:12.683121Z","iopub.status.idle":"2023-01-30T05:55:12.711563Z","shell.execute_reply.started":"2023-01-30T05:55:12.683058Z","shell.execute_reply":"2023-01-30T05:55:12.710309Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"0.7952617563243852\n[-1.23897571e-01  4.81822924e-02 -4.74497796e-02  3.36938950e+00\n -1.56635488e+01  3.59419367e+00 -9.33206067e-03 -1.47089101e+00\n  3.05053544e-01 -1.08397039e-02 -9.08791339e-01  1.00352939e-02\n -4.77714677e-01]\n","output_type":"stream"}]},{"cell_type":"raw","source":"Lasso regression","metadata":{}},{"cell_type":"code","source":"lasso = Lasso(alpha=0.1)\nlasso.fit(X_train,y_train)\ntrain_score=lasso.score(X_train,y_train)\ntest_score=lasso.score(X_test,y_test)\ncoeff_used = np.sum(lasso.coef_!=0)\nprint(test_score)\nprint(lasso.coef_)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T05:55:12.712759Z","iopub.execute_input":"2023-01-30T05:55:12.713385Z","iopub.status.idle":"2023-01-30T05:55:12.729925Z","shell.execute_reply.started":"2023-01-30T05:55:12.713348Z","shell.execute_reply":"2023-01-30T05:55:12.728676Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"0.7781325701654644\n[-0.11469086  0.04982345 -0.09373167  1.60847689 -0.          3.51494142\n -0.01888261 -1.18575423  0.26859655 -0.01204955 -0.73803508  0.01068735\n -0.52980413]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Ridge regression","metadata":{}},{"cell_type":"code","source":"ridge = Ridge(alpha=0.5)\nridge.fit(X_train,y_train)\ntrain_score=ridge.score(X_train,y_train)\ntest_score=ridge.score(X_test,y_test)\ncoeff_used = np.sum(ridge.coef_!=0)\nprint(test_score)\nprint(ridge.coef_)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T05:55:12.731959Z","iopub.execute_input":"2023-01-30T05:55:12.732380Z","iopub.status.idle":"2023-01-30T05:55:12.753403Z","shell.execute_reply.started":"2023-01-30T05:55:12.732345Z","shell.execute_reply":"2023-01-30T05:55:12.751894Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"0.791190045570263\n[-1.21790178e-01  4.84274483e-02 -6.67541535e-02  3.27053220e+00\n -1.10530544e+01  3.63279229e+00 -1.34407097e-02 -1.39938937e+00\n  2.92168740e-01 -1.09981055e-02 -8.54768803e-01  1.02290603e-02\n -4.85349871e-01]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Elastic net","metadata":{}},{"cell_type":"code","source":"elas = ElasticNet(alpha=0.5, l1_ratio=0.5)\nelas.fit(X_train, y_train)\ntrain_score=elas.score(X_train,y_train)\ntest_score=elas.score(X_test,y_test)\nprint(test_score)\n","metadata":{"execution":{"iopub.status.busy":"2023-01-30T05:55:12.754963Z","iopub.execute_input":"2023-01-30T05:55:12.755701Z","iopub.status.idle":"2023-01-30T05:55:12.770164Z","shell.execute_reply.started":"2023-01-30T05:55:12.755657Z","shell.execute_reply":"2023-01-30T05:55:12.769192Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"0.7498390618855599\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Using K-fold cross validation (k=10) to tune the hyper parameter in Lasso regression","metadata":{}},{"cell_type":"code","source":"model = Lasso()\n# define model evaluation method\ncv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n# define grid\ngrid = dict()\ngrid['alpha'] = np.arange(0.001, 1, 0.01)\n# define search\nsearch = GridSearchCV(model, grid, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n# perform the search\nresults = search.fit(xmat, y)\n# summarize\nprint('MAE: %.3f' % results.best_score_)\nprint('Config: %s' % results.best_params_)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T05:55:12.772379Z","iopub.execute_input":"2023-01-30T05:55:12.773570Z","iopub.status.idle":"2023-01-30T05:55:21.424404Z","shell.execute_reply.started":"2023-01-30T05:55:12.773516Z","shell.execute_reply":"2023-01-30T05:55:21.422892Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"MAE: -3.378\nConfig: {'alpha': 0.011}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Using K-fold cross validation to tune the two hyper parameters in elastic net","metadata":{}},{"cell_type":"code","source":"model = ElasticNet()\n# define model evaluation method\ncv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n# define grid\ngrid = dict()\ngrid['alpha'] = np.arange(0.001, 1, 0.2)\ngrid['l1_ratio'] = np.arange(0, 1, 0.2)\n# define search\nsearch = GridSearchCV(model, grid, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n# perform the search\nresults = search.fit(xmat, y)\n# summarize\nprint('MAE: %.3f' % results.best_score_)\nprint('Config: %s' % results.best_params_)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T05:55:21.426896Z","iopub.execute_input":"2023-01-30T05:55:21.428326Z","iopub.status.idle":"2023-01-30T05:55:23.667138Z","shell.execute_reply.started":"2023-01-30T05:55:21.428270Z","shell.execute_reply":"2023-01-30T05:55:23.665864Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.999e+03, tolerance: 3.737e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.155e+03, tolerance: 3.929e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.179e+03, tolerance: 3.890e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.581e+03, tolerance: 3.743e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.945e+03, tolerance: 3.621e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.883e+03, tolerance: 3.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.712e+03, tolerance: 3.587e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.811e+03, tolerance: 3.783e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.812e+03, tolerance: 3.928e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.014e+03, tolerance: 3.887e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.002e+03, tolerance: 3.989e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.082e+03, tolerance: 3.953e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.836e+03, tolerance: 3.806e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.969e+03, tolerance: 4.005e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.859e+03, tolerance: 3.765e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.102e+03, tolerance: 3.798e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.308e+03, tolerance: 3.867e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.755e+03, tolerance: 3.701e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.269e+03, tolerance: 3.966e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.146e+03, tolerance: 3.989e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.306e+03, tolerance: 3.953e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.218e+03, tolerance: 3.996e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.230e+03, tolerance: 3.845e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.171e+03, tolerance: 3.882e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.242e+03, tolerance: 3.822e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.032e+03, tolerance: 3.867e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.899e+03, tolerance: 3.929e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.008e+03, tolerance: 3.954e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.514e+03, tolerance: 3.780e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.524e+03, tolerance: 3.701e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.402e+03, tolerance: 3.822e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.684e+03, tolerance: 3.780e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.069e+03, tolerance: 3.793e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.163e+03, tolerance: 3.962e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.105e+03, tolerance: 3.806e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.257e+03, tolerance: 4.005e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.921e+03, tolerance: 3.766e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.028e+03, tolerance: 3.818e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.056e+03, tolerance: 3.793e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.292e+03, tolerance: 3.962e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.930e+03, tolerance: 3.621e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.952e+03, tolerance: 3.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.327e+03, tolerance: 3.989e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.398e+03, tolerance: 3.953e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.134e+03, tolerance: 3.806e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.840e+03, tolerance: 3.835e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.455e+03, tolerance: 3.587e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.520e+03, tolerance: 3.783e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.702e+03, tolerance: 3.928e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.749e+03, tolerance: 3.887e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.033e+03, tolerance: 3.996e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.001e+03, tolerance: 3.845e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.113e+03, tolerance: 3.798e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.939e+03, tolerance: 3.737e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.471e+03, tolerance: 3.882e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.572e+03, tolerance: 3.822e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.317e+03, tolerance: 3.867e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.202e+03, tolerance: 3.929e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.327e+03, tolerance: 3.954e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.831e+03, tolerance: 3.780e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.260e+03, tolerance: 4.005e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.136e+03, tolerance: 3.765e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.169e+03, tolerance: 3.835e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.736e+03, tolerance: 3.587e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.813e+03, tolerance: 3.783e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.041e+03, tolerance: 3.928e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.041e+03, tolerance: 3.887e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.346e+03, tolerance: 3.996e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.299e+03, tolerance: 3.845e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.330e+03, tolerance: 3.765e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.395e+03, tolerance: 3.835e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.930e+03, tolerance: 3.587e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.018e+03, tolerance: 3.783e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.272e+03, tolerance: 3.928e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.248e+03, tolerance: 3.887e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.831e+03, tolerance: 3.701e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.358e+03, tolerance: 3.966e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.211e+03, tolerance: 3.890e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.802e+03, tolerance: 3.743e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.310e+03, tolerance: 3.798e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.127e+03, tolerance: 3.737e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.679e+03, tolerance: 3.882e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.790e+03, tolerance: 3.822e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.519e+03, tolerance: 3.867e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.416e+03, tolerance: 3.929e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.550e+03, tolerance: 3.954e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.050e+03, tolerance: 3.780e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.044e+03, tolerance: 3.701e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.578e+03, tolerance: 3.966e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.420e+03, tolerance: 3.890e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.044e+03, tolerance: 3.966e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.914e+03, tolerance: 3.890e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.459e+03, tolerance: 3.743e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.609e+03, tolerance: 3.766e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.752e+03, tolerance: 3.818e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.789e+03, tolerance: 3.793e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.972e+03, tolerance: 3.962e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.667e+03, tolerance: 3.621e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.649e+03, tolerance: 3.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.467e+03, tolerance: 3.798e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.278e+03, tolerance: 3.737e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.843e+03, tolerance: 3.882e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.959e+03, tolerance: 3.822e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.680e+03, tolerance: 3.867e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.588e+03, tolerance: 3.929e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.726e+03, tolerance: 3.954e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.222e+03, tolerance: 3.780e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.212e+03, tolerance: 3.701e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.752e+03, tolerance: 3.966e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.585e+03, tolerance: 3.890e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.203e+03, tolerance: 3.743e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.313e+03, tolerance: 3.766e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.383e+03, tolerance: 3.818e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.399e+03, tolerance: 3.793e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.693e+03, tolerance: 3.962e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.261e+03, tolerance: 3.621e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.329e+03, tolerance: 3.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.721e+03, tolerance: 3.989e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.796e+03, tolerance: 3.953e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.512e+03, tolerance: 3.806e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","output_type":"stream"},{"name":"stdout","text":"MAE: -3.379\nConfig: {'alpha': 0.001, 'l1_ratio': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.606e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","output_type":"stream"}]},{"cell_type":"markdown","source":"An illustration of K-fold cross-validation\n\n![image.png](attachment:0e6953c6-9051-4e5d-95ef-301f2cbacba8.png)![image.png](attachment:c6d39fa2-3c9f-4ce5-a0e2-74d0ede83093.png)","metadata":{},"attachments":{"0e6953c6-9051-4e5d-95ef-301f2cbacba8.png":{"image/png":"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"},"c6d39fa2-3c9f-4ce5-a0e2-74d0ede83093.png":{"image/png":"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"}}},{"cell_type":"code","source":"from sklearn.utils import shuffle\ndef cross_validation_split(df, folds):\n    df_copy = df.copy()\n    group_size = int(df_copy.shape[0] / folds)\n        \n    # re-ordering rows of data set randomly\n    df_copy = shuffle(df_copy)\n    lst = [df_copy.iloc[i:i+group_size] for i in range(0,len(df_copy),group_size)]\n    if len(lst[-1]) < group_size:\n        lst.pop()\n    return lst \n\ndef lasso_cv(data_groups, alpha_test):\n    lasso = Lasso(alpha=alpha_test)\n    scores = []\n    for i in range(len(data_groups)):\n        data_copy = data_groups.copy()\n        test_data = data_copy[i]\n        X_test = test_data[X_list]\n        y_test = test_data['Price']\n        data_copy.pop(i)\n        training_data = pd.concat(data_copy)\n        X_train = training_data[X_list] \n        y_train = training_data['Price']\n        lasso.fit(X_train,y_train)\n        test_score=lasso.score(X_test,y_test)\n        scores.append(test_score)\n    return scores\n","metadata":{"execution":{"iopub.status.busy":"2023-01-30T05:55:23.668915Z","iopub.execute_input":"2023-01-30T05:55:23.670300Z","iopub.status.idle":"2023-01-30T05:55:23.682387Z","shell.execute_reply.started":"2023-01-30T05:55:23.670245Z","shell.execute_reply":"2023-01-30T05:55:23.681378Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"d = cross_validation_split(boston_df, 5)\ns = lasso_cv(d, 0.5)\ns","metadata":{"execution":{"iopub.status.busy":"2023-01-30T05:55:23.684013Z","iopub.execute_input":"2023-01-30T05:55:23.684730Z","iopub.status.idle":"2023-01-30T05:55:23.732839Z","shell.execute_reply.started":"2023-01-30T05:55:23.684692Z","shell.execute_reply":"2023-01-30T05:55:23.731417Z"},"trusted":true},"execution_count":74,"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"[0.6461776470647218,\n 0.6719025257135067,\n 0.6206050683681739,\n 0.792090889988631,\n 0.7306115137024412]"},"metadata":{}}]},{"cell_type":"code","source":"np.arange(0.001, 1, 0.2)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T05:55:23.735833Z","iopub.execute_input":"2023-01-30T05:55:23.736224Z","iopub.status.idle":"2023-01-30T05:55:23.745312Z","shell.execute_reply.started":"2023-01-30T05:55:23.736191Z","shell.execute_reply":"2023-01-30T05:55:23.743901Z"},"trusted":true},"execution_count":75,"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"array([0.001, 0.201, 0.401, 0.601, 0.801])"},"metadata":{}}]}]}